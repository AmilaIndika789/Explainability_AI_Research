{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from interpret import show\n",
    "from interpret.blackbox import LimeTabular\n",
    "from interpret.blackbox import ShapKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_csv(\"./data/CEE_DATA.csv\", quotechar=\"'\")\n",
    "\n",
    "X = df[\n",
    "    [\n",
    "        \"Gender\",\n",
    "        \"Caste\",\n",
    "        \"coaching\",\n",
    "        \"time\",\n",
    "        \"Class_ten_education\",\n",
    "        \"twelve_education\",\n",
    "        \"medium\",\n",
    "        \"Class_X_Percentage\",\n",
    "        \"Class_XII_Percentage\",\n",
    "        \"Father_occupation\",\n",
    "        \"Mother_occupation\",\n",
    "    ]\n",
    "]\n",
    "Y = df[\"Performance\"].values.reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_names = {}\n",
    "X_transformed = X.copy()\n",
    "for j, column in enumerate(X.columns):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X[column])\n",
    "    X_transformed[column] = le.transform(X[column])\n",
    "    categorical_names[j] = le.classes_\n",
    "# X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size Instances:  466\n",
      "Test Size Instances: 200\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "seed = 1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_transformed, Y, test_size=0.3, random_state=seed\n",
    ")\n",
    "print(\"Train Size Instances: \", X_train.shape[0])\n",
    "print(\"Test Size Instances:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough', sparse_threshold=0,\n",
       "                  transformers=[('ohe', OneHotEncoder(),\n",
       "                                 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnTransformer = ColumnTransformer([(\"ohe\", OneHotEncoder(), list(categorical_names.keys()))], \n",
    "                                      remainder = 'passthrough',\n",
    "                                      sparse_threshold=0)\n",
    "columnTransformer.fit(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 1., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 1., ..., 1., 0., 0.],\n",
       "       [0., 1., 1., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed = columnTransformer.transform(X_train)\n",
    "X_test_transformed = columnTransformer.transform(X_test)\n",
    "X_test_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME Tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = svm.SVC(probability=True)\n",
    "# clf = naive_bayes.MultinomialNB()\n",
    "# clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_transformed, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x: clf.predict_proba(columnTransformer.transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 0, 2, 0, 1, 2, 3, 3, 0, 3, 2, 2, 1, 1, 2, 2, 0, 2, 3,\n",
       "       3, 0, 2, 0, 3, 3, 2, 0, 2, 0, 2, 3, 0, 0, 3, 0, 2, 0, 0, 1, 0, 3,\n",
       "       1, 0, 2, 1, 0, 0, 1, 0, 2, 2, 2, 0, 2, 2, 2, 3, 3, 3, 2, 1, 0, 1,\n",
       "       2, 2, 0, 0, 1, 2, 2, 3, 3, 2, 2, 1, 2, 2, 2, 2, 0, 0, 2, 3, 3, 1,\n",
       "       3, 1, 2, 2, 3, 1, 3, 0, 3, 2, 0, 2, 3, 3, 2, 1, 3, 1, 2, 1, 2, 2,\n",
       "       3, 2, 3, 3, 0, 2, 2, 0, 2, 3, 3, 1, 2, 3, 2, 2, 1, 2, 0, 3, 2, 0,\n",
       "       0, 2, 3, 3, 3, 2, 3, 2, 0, 1, 2, 0, 3, 2, 0, 3, 0, 0, 1, 3, 1, 2,\n",
       "       2, 2, 2, 0, 2, 2, 3, 3, 3, 0, 0, 2, 3, 3, 1, 3, 2, 1, 3, 1, 2, 2,\n",
       "       3, 2, 2, 3, 0, 2, 2, 2, 0, 1, 3, 1, 2, 2, 0, 1, 3, 2, 0, 0, 3, 1,\n",
       "       3, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lime = LimeTabular(\n",
    "#     predict_fn,\n",
    "#     data=X_train.values,\n",
    "#     feature_names=list(X_train.columns),\n",
    "#     explain_kwargs={\"top_labels\": 3, \"num_features\": 5},\n",
    "#     class_names=clf.classes_.tolist(),\n",
    "#     categorical_features=range(len(X_train.columns)),\n",
    "#     categorical_names=categorical_names,\n",
    "#     kernel_width=3,\n",
    "#     mode='classification'\n",
    "# )\n",
    "# lime_local = lime.explain_local(X_test.values[47], Y_test[47])\n",
    "\n",
    "# show(lime_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 466 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb38e85ecd624fadba5fa6099f9580a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "\n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "\n",
      "The dash_table package is deprecated. Please replace\n",
      "`import dash_table` with `from dash import dash_table`\n",
      "\n",
      "Also, if you're using any of the table format helpers (e.g. Group), replace \n",
      "`from dash_table.Format import Group` with \n",
      "`from dash.dash_table.Format import Group`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/2171280798576/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/2171280798576/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap = ShapKernel(predict_fn=predict_fn, data=X_train.values)\n",
    "shap_local = shap.explain_local(X_test.values[:5], Y_test[:5])\n",
    "\n",
    "show(shap_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
